# T-0015: Launch full training run on ICE

**Status**: DONE
**Phase**: VERIFIED
**After**: â€”
**Before**: â€”

## Context

With the infrastructure verified (Docker image, flash-attn, adam-atan2, wandb online logging, evaluator fix), launch a full training run on the ICE GPU cluster to train the URM model on the ARC dataset.

## Acceptance Criteria

- [x] Training pod launched on ICE with H100 GPU(s)
- [x] Training script running with production config
- [x] Wandb logging online and visible
- [x] Training progressing without errors

## Verification Plan

### Tests to Create
| Test | Proves | Status |
|------|--------|--------|
| Manual: Check pod status | Pod running on H100 | - |
| Manual: Check wandb.ai | Metrics logging online | - |

### Regression Check
```
kubectl get pods -n aic | grep urm
```

### Manual Verification
- [ ] Verify pod is running on H100
- [ ] Verify wandb run visible at wandb.ai
- [ ] Verify training loss decreasing

## Approach

1. Launch pod with 8 H100 GPUs using train.sh
2. Sync code and data
3. Start distributed training with torchrun

## Implementation Notes

### PLANNING
- Use 8 H100 GPUs for training (full node)
- Data: arc1concept-aug-100 (complete with test data)
- Config: URM with loops=16, H_cycles=2, L_cycles=6, num_layers=4

### IMPLEMENTING
1. First attempt failed with shared memory error (DataLoader workers)
2. Updated train.sh to add `/dev/shm` volume (64Gi memory-backed)
3. Fixed Hydra config: `ema=True` â†’ `+ema=True`
4. Relaunched pod with shm fix
5. Training started successfully

### DEBUGGING
- **Issue 1**: `ema` key not in struct â†’ Use `+ema=True` prefix
- **Issue 2**: DataLoader workers out of shared memory â†’ Add dshm volume mount with 64Gi

## Obstacles

### Resolved: Shared Memory Limit
DataLoader workers killed by Bus error due to insufficient /dev/shm. Fixed by adding memory-backed emptyDir volume.

### Resolved: Hydra Config
`ema=True` failed because key doesn't exist in base config. Need `+ema=True` to add new key.

## Evidence

```
$ kubectl get pods -n aic | grep urm
urm-arcagi1-full       1/1     Running   0          3m

$ kubectl exec -n aic urm-arcagi1-full -- tail -5 /workspace/training.log
  0%|          | 28/1038102 [02:08<164:16:50,  1.76it/s]

wandb: ðŸš€ View run at https://wandb.ai/sverker-janson-rise/arcagi/runs/z6p67p67
```

## Outcome

Successfully launched full training run on ICE:
- Pod: urm-arcagi1-full (8x H100)
- Data: arc1concept-aug-100
- Wandb: https://wandb.ai/sverker-janson-rise/arcagi/runs/z6p67p67
- Training speed: ~1.76 it/s
